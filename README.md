# Airflow 2.8.0 Project Boilerplate

## Installation and Initial Setup

### Setting up Docker and Docker Compose
Follow installation guide to install Docker and Docker Compose below:
- https://docs.docker.com/engine/installation/
- https://docs.docker.com/compose/install/

### Setting up Apache Airflow
Follow installation guide to install and run Airflow below:
- https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#fetching-docker-compose-yaml

Include additional directories by creating subfolders under the project folder:
```bash
mkdir -p ./dags/include/global_variables ./dags/include/hooks ./dags/include/operators ./dags/include/sensors ./data ./utils
```

Note 2: To run Airflow, use the command below instead to run Docker containers in detached mode or get started in the background and the command prompt or terminal will be released. Remove the ```-d``` flag to view the logs in the terminal.
```bash
docker compose up -d
```

### Setting up hooks and other providers

Install hooks and other providers like that of MongoDB and Redis by adding the following in the requirements.txt:
```
apache-airflow-providers-mongo
apache-airflow-providers-redis
<insert other provider here>
```

Create a Dockerfile file in the project root directory and include the following:
```
FROM apache/airflow:2.8.0
COPY requirements.txt /requirements.txt
RUN pip install --user --upgrade pip
RUN pip install --no-cache-dir --user -r /requirements.txt
```

After that, run ```docker build . --tag <name_of_image>:latest --no-cache``` for rebuilding. You can specify the new name of the image in the docker-compose.yml file.


### Mounting airflow.cfg

If airflow.cfg file is missing in the config/ directory, run the following command:
```bash
airflow config list --defaults
```

The command will produce the output that can be copied to the configuration file and edit. It will contain all the default configuration options, with examples, nicely commented out so one need only un-comment and modify those that one want to change.

Run the following command to save the default configuration to config/ directory:

```bash
airflow config list --defaults > config/airflow.cfg
```

To mount on the docker-compose.yml, add the following as a volume under x-airflow-common:
```bash
${AIRFLOW_PROJ_DIR:-.}/config/airflow.cfg:/opt/airflow/airflow.cfg
```

Run ```docker compose up -d``` to run and reflect the changes.


## Project Structure

```
airflow_project/
│
├── dags/
│   ├── include/
│   │   ├── global_variables/
│   │   │   ├── airflow_conf_variables.py	
│   │   │   └── constants.py
│   │   │
│   │   ├── hooks/
│   │   │   ├── custom_hook_1.py	
│   │   │   ├── custom_hook_2.py	
│   │   │   └── custom_hook_n.py  	
│   │   │
│   │   ├── operators/
│   │   │   ├── custom_operator_1.py	
│   │   │   ├── custom_operator_2.py	
│   │   │   └── custom_operator_n.py  	
│   │   │
│   │   └── sensors/
│   │       ├── custom_sensor_1.py	
│   │       ├── custom_sensor_2.py	
│   │       └── custom_sensor_n.py  	
│   │
│   ├── start_dag.py 
│   ├── dag_1.py		
│   ├── dag_2.py
│   └── dag_n.py
│
├── plugins/
│
├── config/
│   └── airflow.cfg
│
├── data/			
│
├── logs/		
│
├── utils/	
│   └── helpers.py		
│
├── .dockerignore
├── .env
├── .gitignore
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
└── README.md
```

### dags/
Contains the DAGs definition and supporting Python files.

- **start_dag.py** - DAG that kicks off the pipeline by setting up a new Airflow pool.
- **dag_n.py** - DAGs written in TaskFlow API for better maintainability.

#### include/
Contains external Python files needed by DAGs to execute.

- **global_variables/airflow_conf_variables.py** - Contains global variables that affect Airflow configuration.
- **global_variables/constants.py** - Contains global variables for database names, paths, ports, etc. Alternative to Web UI counterpart.

#### plugins/
Contains custom operators, sensors, hooks.

- **hooks/** - Directory for custom hooks.
- **operators/** - Directory for custom operators.
- **sensors/** - Directory for custom sensors.

### config/
Contains Airflow configuration file.

- **airflow.cfg** - Airflow config file to be mounted on docker-compose.yml

### data/
Contains files needed and/or generated by DAGs.

### logs/
Contains log files of DAGs, scheduler, process manager, etc.

### utils/
Contains utility and helper functions.
- **helpers.py** - Contains functions that provide common functionalities needed by DAGs.

### Other files

- **.dockerignore** - Specifies files and directories that are excluded in building the Docker image.
- **.env** - Stores environment variables (should specify if for development or production).
- **Dockerfile** - Contains a set of instructions for building a Docker image.
- **docker-compose.yml** - Defines the services, networks, and volumes of the Docker image.
- **requirements.txt** - Specifies the dependencies (libraries and packages) required by the project.
- **README.md** - Documentation file of the project.

